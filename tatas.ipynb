{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np \nimport pandas as pd \nimport pickle\nimport torch\nfrom matplotlib import pyplot as plt \nimport torchvision.models as models\nfrom torchvision import transforms\nimport torch.nn as nn \nfrom tqdm import tqdm, tqdm_notebook\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nfrom IPython.display import clear_output\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nfrom pathlib import Path\nfrom torch.utils.data import Dataset, DataLoader\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:58:55.438420Z","iopub.execute_input":"2022-04-12T08:58:55.438740Z","iopub.status.idle":"2022-04-12T08:59:22.958744Z","shell.execute_reply.started":"2022-04-12T08:58:55.438652Z","shell.execute_reply":"2022-04-12T08:59:22.957997Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:22.960448Z","iopub.execute_input":"2022-04-12T08:59:22.960795Z","iopub.status.idle":"2022-04-12T08:59:23.414189Z","shell.execute_reply.started":"2022-04-12T08:59:22.960748Z","shell.execute_reply":"2022-04-12T08:59:23.413514Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df1 = df.pivot(index='ImageId', columns='ClassId', values='EncodedPixels')\ndf1.reset_index(inplace=True)\nd = {'ImageId': df1['ImageId'], '1': df1[1], '2': df1[2], '3': df1[3], '4': df1[4]}\ntrain_df = pd.DataFrame(d)\ntrain_df.fillna('',inplace=True)\ntrain_df['ClassesList'] = (train_df.iloc[:,1:]!='').astype(np.int8).values.tolist()\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:23.415376Z","iopub.execute_input":"2022-04-12T08:59:23.415605Z","iopub.status.idle":"2022-04-12T08:59:23.465319Z","shell.execute_reply.started":"2022-04-12T08:59:23.415572Z","shell.execute_reply":"2022-04-12T08:59:23.464671Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"d1 = {'ImageId': train_df['ImageId'], 'ClassesList': train_df['ClassesList']}\ntrain_df1 = pd.DataFrame(d1)\ntrain_df1['EncodedPixels'] = train_df1['ClassesList']\nfor i in range(6666):\n    c = []\n    v = ['1', '2', '3','4']\n    for j in range(4):\n        if train_df[v[j]][i] != '':\n            c.append(train_df[v[j]][i])\n    train_df1['EncodedPixels'][i] = c\ntrain_df1.head(13)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:23.467078Z","iopub.execute_input":"2022-04-12T08:59:23.467636Z","iopub.status.idle":"2022-04-12T08:59:25.806001Z","shell.execute_reply.started":"2022-04-12T08:59:23.467600Z","shell.execute_reply":"2022-04-12T08:59:25.805322Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def make_mask( encoded, shape=(1600,256)):\n    # Инициализируем закодированные пиксели\n    # encoded = df['EncodedPixels'].iloc[idx]\n    # Делим на два списка в соответствии с кодировкой\n    if isinstance(encoded, str):\n        encoded = list(map(int, encoded.split(' ')))\n#     print(encoded)\n    full,pixel,number = [],[],[]\n    [pixel.append(encoded[i]) if i%2==0 else number.append(encoded[i]) for i in range(0, len(encoded))]\n    # \"Раскрываем\" кодировку, получаем индексы закрашенных пикселей\n    k=0\n    for i in range(len(number)):\n        for j in range(number[i]):\n            ind = pixel[i]+j\n            full.append(ind-1)\n        k +=number[i]\n    # Создаем массив под готовое изображение    \n    mask = np.zeros((1600*256,1), dtype=int)\n    # Закрашиваем соответствующие пиксели\n    mask[full] = 255\n#     for p, n in zip(pixel, number):\n#         mask[p:p + n] = 255\n    #преобразем к размерам фотографий металла\n    res = np.reshape(mask,(1600, 256)).T\n    res = Image.fromarray(res.astype(np.uint8))\n    \n    return res","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:25.807123Z","iopub.execute_input":"2022-04-12T08:59:25.807394Z","iopub.status.idle":"2022-04-12T08:59:25.816219Z","shell.execute_reply.started":"2022-04-12T08:59:25.807359Z","shell.execute_reply":"2022-04-12T08:59:25.815534Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:25.817640Z","iopub.execute_input":"2022-04-12T08:59:25.818364Z","iopub.status.idle":"2022-04-12T08:59:25.879885Z","shell.execute_reply.started":"2022-04-12T08:59:25.818270Z","shell.execute_reply":"2022-04-12T08:59:25.879094Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# разные режимы датасета \nDATA_MODES = ['train', 'val', 'test']\n# все изображения будут масштабированы к размеру 224x224 px\nRESCALE_SIZE_1 = 800\nRESCALE_SIZE_2 = 128\n# работаем на видеокарте\nDEVICE = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:25.881076Z","iopub.execute_input":"2022-04-12T08:59:25.881886Z","iopub.status.idle":"2022-04-12T08:59:25.889027Z","shell.execute_reply.started":"2022-04-12T08:59:25.881848Z","shell.execute_reply":"2022-04-12T08:59:25.888344Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SteelDataset(Dataset):\n    def __init__(self, names, df, mode):\n        super().__init__()\n        self.names = names\n        self.mode = mode\n        if self.mode != 'test':\n            self.df = df\n\n        if self.mode not in DATA_MODES:\n            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n            raise NameError\n\n        self.len_ = len(self.names)\n        \n    def __len__(self):\n        return self.len_\n      \n    def load_sample(self, file, mode):\n#         image = cv2.imread('../input/severstal-steel-defect-detection/train_images/'+ file, cv2.IMREAD_UNCHANGED)\n        if mode == 'test':\n            image = Image.open('../input/severstal-steel-defect-detection/test_images/'+ file).convert(\"RGB\")\n        else:\n            image = Image.open('../input/severstal-steel-defect-detection/train_images/'+ file).convert(\"RGB\")\n        image.load()\n#         print(np.array(image).shape)\n        return image\n    \n    def __getitem__(self, index):\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n#            transforms.RandomHorizontalFlip(),\n#              transforms.Normalize([0.485], [0.229]) \n        ])\n        img = self.load_sample(self.names[index], self.mode)\n        img = self._prepare_sample(img)\n        img = np.array(img)\n        max_value = 256 ** ((img.dtype == np.uint16) + 1) - 1\n        img = (img / max_value).astype(np.float32)\n        img = transform(img)\n\n        if self.mode == 'test':\n            return img\n        else:\n            masks = list(self.df['EncodedPixels'].loc[self.df['ImageId'] == self.names[index]])\n            mask = []\n            \n            for i in range(len(masks[0])):\n                mask.append(np.array(self._prepare_sample(make_mask(masks[0][i]))))\n            \n            num_objs = len(masks[0])\n            boxes = []\n            for i in range(num_objs):\n                pos = np.where(mask[i])\n                xmin = np.min(pos[1])\n                xmax = np.max(pos[1])\n                ymin = np.min(pos[0])\n                ymax = np.max(pos[0])\n                boxes.append([xmin, ymin, xmax, ymax])\n            mask = np.array(mask)\n            mask = mask / 255\n            mask = torch.as_tensor(mask, dtype=torch.uint8)\n            labels = list(self.df['ClassesList'].loc[self.df['ImageId'] == self.names[index]])\n            cls = []\n            for i in range(4):\n                if labels[0][i]!=0:\n                    cls.append(i+1)\n            label = torch.as_tensor(cls)\n                \n            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n            iscrowd = torch.zeros((num_objs,), dtype=torch.uint8)\n            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n            image_id = torch.tensor([index])\n            \n            target = {}\n            target[\"boxes\"] = boxes\n            target[\"labels\"] = label\n            target[\"image_id\"] = image_id\n            target[\"area\"] = area\n            target[\"iscrowd\"] = iscrowd\n            target[\"masks\"] = mask\n            \n#             print(img)\n#             print(len(target))\n#             print(\"boxes\", target[\"boxes\"].shape,target[\"boxes\"].dtype)\n#             print(\"labels\", target[\"labels\"].shape, target[\"labels\"].dtype)\n#             print(\"image_id\", target[\"image_id\"].shape, target[\"image_id\"].dtype)\n#             print(\"area\", target[\"area\"].shape, target[\"area\"].dtype)\n#             print(\"iscrowd\", target[\"iscrowd\"].shape,target[\"iscrowd\"].dtype)\n#             print(\"masks\", target[\"masks\"].shape, target[\"masks\"].dtype)\n#             img = transform(img)\n#             target[\"masks\"] = transform(target[\"masks\"])\n            return img, target\n        \n    def _prepare_sample(self, image):\n#         print(image.shape)\n        image = image.resize((RESCALE_SIZE_1, RESCALE_SIZE_2))\n#         image = cv2.resize(src=image, dsize=(image.shape[0], RESCALE_SIZE_2, RESCALE_SIZE_1))\n#         print(image.shape)\n        return np.array(image)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:25.890290Z","iopub.execute_input":"2022-04-12T08:59:25.890626Z","iopub.status.idle":"2022-04-12T08:59:25.912763Z","shell.execute_reply.started":"2022-04-12T08:59:25.890571Z","shell.execute_reply":"2022-04-12T08:59:25.911920Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_val_names = train_df['ImageId']\ntrain_files,val_files = train_test_split(train_val_names, train_size=0.75)\nval_dataset = SteelDataset(list(val_files), train_df1,  mode='val')\ntrain_dataset = SteelDataset(list(train_files),train_df1, mode='train')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:25.915336Z","iopub.execute_input":"2022-04-12T08:59:25.915823Z","iopub.status.idle":"2022-04-12T08:59:25.965933Z","shell.execute_reply.started":"2022-04-12T08:59:25.915783Z","shell.execute_reply":"2022-04-12T08:59:25.965296Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:25.968866Z","iopub.execute_input":"2022-04-12T08:59:25.969272Z","iopub.status.idle":"2022-04-12T08:59:25.972662Z","shell.execute_reply.started":"2022-04-12T08:59:25.969240Z","shell.execute_reply":"2022-04-12T08:59:25.972001Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def load_model():\n    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n\n    # get the number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 5)\n\n    # now get the number of input features for the mask classifier\n    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n    hidden_layer = 256\n    # and replace the mask predictor with a new one\n    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n                                                       hidden_layer,\n                                                       5)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:25.973799Z","iopub.execute_input":"2022-04-12T08:59:25.974589Z","iopub.status.idle":"2022-04-12T08:59:25.981726Z","shell.execute_reply.started":"2022-04-12T08:59:25.974553Z","shell.execute_reply":"2022-04-12T08:59:25.980997Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def fit_epoch(model, train_loader, criterion, optimizer, batch_size):\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n#     print(len(train_loader))\n    for inputs, labels in train_loader:\n#         print(np.array(inputs).shape)\n#         inputs = list(input for input in inputs)\n#         labels = [{k: v for k, v in t.items()} for t in labels]\n        inputs = list((input.float()).to(DEVICE) for input in inputs)\n        labels = [{k: v.to(DEVICE) for k, v in t.items()} for t in labels]\n        optimizer.zero_grad()\n        outputs = model(inputs, labels)\n        loss = sum(x for x in outputs.values())\n        loss.backward()\n        optimizer.step()\n#         preds = torch.sigmoid(outputs) \n        running_loss += loss.item() #* inputs.size(0)\n#         running_corrects += dice_coef(preds, labels) #написать функцию\n#         print(inputs.dtype)\n#         print(np.asarray(inputs).dtype)\n#         processed_data += np.asarray(input).size(0)\n              \n#     train_loss = running_loss / processed_data\n#     train_acc = running_corrects.cpu().numpy() / processed_data\n    train_loss = running_loss / len(train_loader)\n    return train_loss\n#     return train_loss, train_acc","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:25.982994Z","iopub.execute_input":"2022-04-12T08:59:25.983667Z","iopub.status.idle":"2022-04-12T08:59:25.991999Z","shell.execute_reply.started":"2022-04-12T08:59:25.983630Z","shell.execute_reply":"2022-04-12T08:59:25.991267Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def eval_epoch(model, val_loader, criterion, batch_size):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    loss = 0\n    loss_mask = 0\n    for inputs, labels in val_loader:\n#         print([len(a) for a in inputs])\n#         inputs = list(input for input in inputs)\n#         labels = [{k: v for k, v in t.items()} for t in labels]\n        inputs = list((input.float()).to(DEVICE) for input in inputs)\n        labels = [{k: v.to(DEVICE) for k, v in t.items()} for t in labels]\n#         inputs = inputs.to(DEVICE)\n#         labels = labels.to(DEVICE)\n\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs,labels)\n#             print(outputs)\n#             print(outputs[0]['scores'])\n#             loss_mask = \n            for x in range(len(outputs)):\n                loss += sum(loss for loss in outputs[x]['scores'])\n#             loss = sum(x for x in outputs.values())\n#             loss = bce_dice_loss(labels, outputs)\n#             preds = torch.sigmoid(outputs)\n        running_loss += loss # * inputs.size(0)\n#         running_corrects += dice_coef(preds,labels)  #написать функцию\n#         processed_size += np.array(inputs).size(0)\n    val_loss = running_loss / len(val_loader)\n#     val_loss = running_loss / processed_size\n#     val_acc = running_corrects.double() / processed_size\n#     return val_loss, val_acc\n    # Visualize tools\n    clear_output(wait=True)\n    \n#     print(outputs[0][\"masks\"].dtype)\n#     print(outputs[0][0,0][\"masks\"])\n#     plt.figure(figsize=(10,10))\n    plt.figure(figsize=(13, 9))\n    for k in range(2): \n        plt.subplot(3, 2, k+1)\n        plt.imshow(np.rollaxis(inputs[k].detach().cpu().numpy(), 0, 3), cmap='gray')\n        plt.title('Real')\n        plt.axis('off')\n        \n        plt.subplot(3, 2, k+3)\n#         print(labels[k][\"masks\"].detach().cpu().numpy()[0])\n#         print(labels[k][\"masks\"].detach().cpu().numpy()[0].shape)\n#         print(len(labels[k][\"masks\"].detach().cpu().numpy()))\n        plt.imshow(np.sum(labels[k][\"masks\"].detach().cpu().numpy(),0), cmap='gray')\n        plt.title('True' +'\\n' + str(labels[k][\"labels\"]))\n        plt.axis('off')\n        \n        if outputs[k][\"masks\"].detach().cpu().numpy().size != 0:\n            plt.subplot(3, 2, k+5)\n#             outputs[k][\"masks\"] = torch.as_tensor(outputs[k][\"masks\"], dtype=torch.float32)\n            plt.imshow(np.sum(outputs[k][\"masks\"].detach().cpu().numpy(),0).squeeze(), cmap='gray')\n            plt.title('Output'+'\\n'+str(outputs[k][\"labels\"]))\n            plt.axis('off')\n    plt.show()\n    return val_loss","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:25.994054Z","iopub.execute_input":"2022-04-12T08:59:25.994237Z","iopub.status.idle":"2022-04-12T08:59:26.010721Z","shell.execute_reply.started":"2022-04-12T08:59:25.994214Z","shell.execute_reply":"2022-04-12T08:59:26.010080Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:26.011978Z","iopub.execute_input":"2022-04-12T08:59:26.012439Z","iopub.status.idle":"2022-04-12T08:59:26.021647Z","shell.execute_reply.started":"2022-04-12T08:59:26.012403Z","shell.execute_reply":"2022-04-12T08:59:26.020764Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def train(train_files, val_files, model, epochs, batch_size):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size,num_workers = 2, shuffle=True,collate_fn = collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size,num_workers = 2, shuffle=False,collate_fn = collate_fn)\n#     print(train_loader)\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n    criterion = 0\n    \n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        params = [p for p in model.parameters() if p.requires_grad]\n        opt =  torch.optim.SGD(params, lr=0.0005,\n                            momentum=0.9, weight_decay=0.0005)\n#         lr_scheduler = torch.optim.lr_scheduler.StepLR(opt,\n#                                                    step_size=10,\n#                                                    gamma=0.1)\n        for epoch in range(epochs):\n#         train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n            train_loss = fit_epoch(model, train_loader, criterion, opt, batch_size)\n#          print(\"loss\", train_loss)\n#             lr_scheduler.step()    \n#          val_loss, val_acc = eval_epoch(model, val_loader, criterion, batch_size)\n            val_loss = eval_epoch(model, val_loader, criterion, batch_size)\n#           history.append((train_loss, train_acc, val_loss, val_acc))\n            history.append((train_loss, 0, val_loss, 0))\n#           print(\"loss\", val_loss)\n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n                                           v_loss=val_loss, t_acc=0, v_acc=0))\n            \n    return history","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:26.023061Z","iopub.execute_input":"2022-04-12T08:59:26.023564Z","iopub.status.idle":"2022-04-12T08:59:26.033679Z","shell.execute_reply.started":"2022-04-12T08:59:26.023527Z","shell.execute_reply":"2022-04-12T08:59:26.032998Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = load_model()\nmodel.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:26.035112Z","iopub.execute_input":"2022-04-12T08:59:26.035641Z","iopub.status.idle":"2022-04-12T08:59:41.693443Z","shell.execute_reply.started":"2022-04-12T08:59:26.035604Z","shell.execute_reply":"2022-04-12T08:59:41.692598Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"history = train(train_dataset, val_dataset, model, epochs = 30, batch_size = 15)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:59:41.694862Z","iopub.execute_input":"2022-04-12T08:59:41.695320Z","iopub.status.idle":"2022-04-12T12:35:45.016615Z","shell.execute_reply.started":"2022-04-12T08:59:41.695277Z","shell.execute_reply":"2022-04-12T12:35:45.015821Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"loss, acc, val_loss, val_acc = zip(*history)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:45.018468Z","iopub.execute_input":"2022-04-12T12:35:45.020132Z","iopub.status.idle":"2022-04-12T12:35:45.025350Z","shell.execute_reply.started":"2022-04-12T12:35:45.020086Z","shell.execute_reply":"2022-04-12T12:35:45.024275Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\nplt.plot(loss, label=\"train_loss\")\n# plt.plot(val_loss.cpu(), label=\"val_loss\")\n# plt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:45.026888Z","iopub.execute_input":"2022-04-12T12:35:45.027156Z","iopub.status.idle":"2022-04-12T12:35:45.242485Z","shell.execute_reply.started":"2022-04-12T12:35:45.027122Z","shell.execute_reply":"2022-04-12T12:35:45.241822Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"cpu_device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:45.243887Z","iopub.execute_input":"2022-04-12T12:35:45.244326Z","iopub.status.idle":"2022-04-12T12:35:45.248555Z","shell.execute_reply.started":"2022-04-12T12:35:45.244287Z","shell.execute_reply":"2022-04-12T12:35:45.247786Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_loader,df):\n    model.eval()\n    j = 0\n    for inputs in test_loader:\n#         logits = []\n        inputs = list((input.float()).to(DEVICE) for input in inputs)\n#         with torch.no_grad():\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n            for i in range(len(inputs)):\n                for k in range(len(outputs[i]['masks'])):\n                    for n in range(4):\n                        if outputs[i]['labels'][k] == n+1:\n                            if df['EncodedPixels'][i+j*5][n] == []:\n                                df['EncodedPixels'][i+j*5][n].append(outputs[i]['masks'][k].numpy())\n                            else:\n#                                 print(df['EncodedPixels'][i+j*5][n][0])\n                                df['EncodedPixels'][i+j*5][n] = df['EncodedPixels'][i+j*5][n][0]+outputs[i]['masks'][k].numpy()\n#                 df['EncodedPixels'][i+j*5].append(outputs[i]['masks'])\n                df['ClassId'][i+j*5]= np.unique(outputs[i]['labels'].numpy())\n#                 print(df.head())\n            if j ==100  or j == 0 or j == 500 or j == 1000:\n                print(j)\n            j+=1\n#             logits.append(outputs)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:45.249854Z","iopub.execute_input":"2022-04-12T12:35:45.250259Z","iopub.status.idle":"2022-04-12T12:35:45.262578Z","shell.execute_reply.started":"2022-04-12T12:35:45.250224Z","shell.execute_reply":"2022-04-12T12:35:45.261671Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def predict_one_random_sample(model, dataset):\n    i = int(np.random.uniform(0,500))\n    inputs = test_dataset[i]\n    plt.figure(figsize=(13, 9))\n    plt.imshow(np.rollaxis(inputs.numpy(), 0, 3), cmap='gray')\n    plt.title('input')\n    plt.axis('off')\n    plt.show()\n    \n    with torch.no_grad():\n        inputs = [inputs.to(DEVICE)]\n        model.eval()\n        outputs = model(inputs)\n\n    plt.figure(figsize=(13, 9))\n    plt.imshow(np.sum(outputs[0]['masks'].detach().cpu().numpy(),0).squeeze(), cmap='gray')\n    plt.title('Output'+'\\n'+str(outputs[0]['labels']))\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:45.265064Z","iopub.execute_input":"2022-04-12T12:35:45.265463Z","iopub.status.idle":"2022-04-12T12:35:45.274469Z","shell.execute_reply.started":"2022-04-12T12:35:45.265424Z","shell.execute_reply":"2022-04-12T12:35:45.273678Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"TEST_DIR = Path('../input/severstal-steel-defect-detection/test_images')\ntest_files = sorted(list(TEST_DIR.rglob('*.jpg')))\nfor i in range(len(test_files)):\n    test_files[i] = str(test_files[i]).replace('../input/severstal-steel-defect-detection/test_images/', '')\n\ntest_dataset = SteelDataset(test_files,df, mode=\"test\")\nlen(test_files)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:45.275764Z","iopub.execute_input":"2022-04-12T12:35:45.276028Z","iopub.status.idle":"2022-04-12T12:35:48.090448Z","shell.execute_reply.started":"2022-04-12T12:35:45.275994Z","shell.execute_reply":"2022-04-12T12:35:48.089807Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"predict_one_random_sample(model, test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:48.094051Z","iopub.execute_input":"2022-04-12T12:35:48.094541Z","iopub.status.idle":"2022-04-12T12:35:48.783121Z","shell.execute_reply.started":"2022-04-12T12:35:48.094503Z","shell.execute_reply":"2022-04-12T12:35:48.782270Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, shuffle=False, batch_size=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:48.787538Z","iopub.execute_input":"2022-04-12T12:35:48.788222Z","iopub.status.idle":"2022-04-12T12:35:48.796516Z","shell.execute_reply.started":"2022-04-12T12:35:48.788163Z","shell.execute_reply":"2022-04-12T12:35:48.795814Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"d = {'ImageId': test_files}\ntest_df = pd.DataFrame(d)\ntest_df['EncodedPixels'] = [[[],[],[],[]] for i in range(len(test_files))]\ntest_df['ClassId'] = [[] for i in range(len(test_files))]","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:36:12.592826Z","iopub.execute_input":"2022-04-12T12:36:12.593589Z","iopub.status.idle":"2022-04-12T12:36:12.609798Z","shell.execute_reply.started":"2022-04-12T12:36:12.593546Z","shell.execute_reply":"2022-04-12T12:36:12.609017Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"probs = predict(model, test_loader,test_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:36:14.456515Z","iopub.execute_input":"2022-04-12T12:36:14.456785Z","iopub.status.idle":"2022-04-12T12:41:57.511739Z","shell.execute_reply.started":"2022-04-12T12:36:14.456756Z","shell.execute_reply":"2022-04-12T12:41:57.510830Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"probs.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:49:56.055765Z","iopub.execute_input":"2022-04-12T12:49:56.056029Z","iopub.status.idle":"2022-04-12T12:50:13.510470Z","shell.execute_reply.started":"2022-04-12T12:49:56.056000Z","shell.execute_reply":"2022-04-12T12:50:13.509763Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"probs['EncodedPixels'][2][0]","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:59.487330Z","iopub.status.idle":"2022-04-12T12:35:59.488130Z","shell.execute_reply.started":"2022-04-12T12:35:59.487871Z","shell.execute_reply":"2022-04-12T12:35:59.487902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open('../input/severstal-steel-defect-detection/test_images/'+ probs['ImageId'][2]).convert(\"RGB\")\nimg.load()\nimg = img.resize((800, 128))\nplt.figure(figsize=(13, 9))\nplt.imshow(img, cmap='gray')\nplt.axis('off')\nplt.show()\nplt.figure(figsize=(13, 9))\nplt.imshow((probs['EncodedPixels'][2][0]+probs['EncodedPixels'][2][2]).squeeze(), cmap='gray')\nplt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:59.489274Z","iopub.status.idle":"2022-04-12T12:35:59.490088Z","shell.execute_reply.started":"2022-04-12T12:35:59.489813Z","shell.execute_reply":"2022-04-12T12:35:59.489841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def from_mask_to_encoding(mask):\n#     print(mask.shape)\n#     plt.figure(figsize=(13, 9))\n#     plt.imshow(mask, cmap='gray')\n#     plt.axis('off')\n#     plt.show()\n#     mask = Image.fromarray(mask.astype(np.uint8))\n#     plt.figure(figsize=(13, 9))\n#     plt.imshow(mask, cmap='gray')\n#     plt.axis('off')\n#     plt.show()\n#     mask = mask.resize((1600, 256))\n#     plt.figure(figsize=(13, 9))\n#     plt.imshow(mask, cmap='gray')\n#     plt.axis('off')\n#     plt.show()\n#     mask = np.array(mask)\n#     print(mask)\n    if mask.shape[0]==128:\n        pixels= mask.T.flatten()\n    else:\n        pixels= mask.T\n    pixels = np.concatenate([[0], pixels, [0]])\n#     print(pixels)\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[:-1:2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:32:20.390780Z","iopub.execute_input":"2022-04-12T13:32:20.391480Z","iopub.status.idle":"2022-04-12T13:32:20.397360Z","shell.execute_reply.started":"2022-04-12T13:32:20.391445Z","shell.execute_reply":"2022-04-12T13:32:20.396655Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# def from_mask_to_encoding(mask):\n\n#     flat = mask.flatten()\n\n#     padded = np.concatenate([[0], flat, [0]])\n    \n#     runs = np.where(padded[1:] != padded[:-1])[0] \n#     runs += 1\n#     runs[1::2] -= runs[0::2]\n#     return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T12:35:59.493217Z","iopub.status.idle":"2022-04-12T12:35:59.493992Z","shell.execute_reply.started":"2022-04-12T12:35:59.493729Z","shell.execute_reply":"2022-04-12T12:35:59.493758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_files_result = []\nfor i in range(len(test_files)):\n    for j in range(4):\n        test_files_result.append(test_files[i])\nd1 = {'ImageId': test_files_result}\nres_df = pd.DataFrame(d1)\nres_df['EncodedPixels'] = ['' for i in range(len(test_files_result))]\nres_df['ClassId'] = [0 for i in range(len(test_files_result))]\nres_df.head(8)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:37:30.327915Z","iopub.execute_input":"2022-04-12T13:37:30.328306Z","iopub.status.idle":"2022-04-12T13:37:30.375451Z","shell.execute_reply.started":"2022-04-12T13:37:30.328269Z","shell.execute_reply":"2022-04-12T13:37:30.374656Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"for i in range(len(test_files)):\n    for j in range(4):\n#         if probs['EncodedPixels'][i][j] != []:\n#             print(probs['EncodedPixels'][i][j][0][0], i,j)\n#             print(from_mask_to_encoding(probs['EncodedPixels'][i][j][0][0]))\n#             res_df['EncodedPixels'][4*i+j].append(from_mask_to_encoding(probs['EncodedPixels'][i][j][0][0]))\n        for k in range(len(probs['ClassId'][i])):\n            if probs['ClassId'][i][k] ==j+1:\n                res_df['ClassId'][4*i+j] = probs['ClassId'][i][k]\n                res_df['EncodedPixels'][4*i+j]= from_mask_to_encoding(probs['EncodedPixels'][i][j][0][0])\nres_df.head(8)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:37:33.338656Z","iopub.execute_input":"2022-04-12T13:37:33.338921Z","iopub.status.idle":"2022-04-12T13:38:30.360494Z","shell.execute_reply.started":"2022-04-12T13:37:33.338892Z","shell.execute_reply":"2022-04-12T13:38:30.359813Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"for i in range(len(res_df)):\n    if res_df['ClassId'][i]==0:\n        res_df['ClassId'][i]=''","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:39:58.347328Z","iopub.execute_input":"2022-04-12T13:39:58.347589Z","iopub.status.idle":"2022-04-12T13:39:58.615873Z","shell.execute_reply.started":"2022-04-12T13:39:58.347561Z","shell.execute_reply":"2022-04-12T13:39:58.615152Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"res_df.to_csv('./simple_cnn_baseline.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:46:43.203332Z","iopub.execute_input":"2022-04-12T13:46:43.203602Z","iopub.status.idle":"2022-04-12T13:46:51.303141Z","shell.execute_reply.started":"2022-04-12T13:46:43.203576Z","shell.execute_reply":"2022-04-12T13:46:51.302363Z"},"trusted":true},"execution_count":105,"outputs":[]}]}